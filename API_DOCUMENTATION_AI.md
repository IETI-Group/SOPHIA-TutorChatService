# Documentaci√≥n de la API del Servicio de IA

Esta documentaci√≥n detalla c√≥mo configurar, ejecutar y utilizar los servicios de Inteligencia Artificial integrados en SOPHIA Coordinator.

---

## üì° Endpoints de la API

URL Base: `/api/v1/ai`

### 1. Chat con IA

Permite interactuar con el modelo de IA. Todos los mensajes se guardan autom√°ticamente en la base de datos.

**Endpoint:** `POST /chat`

#### Cuerpo de la Petici√≥n (Request Body)

| Campo | Tipo | Requerido | Descripci√≥n |
|-------|------|----------|-------------|
| `message` | string | S√≠ | El mensaje actual que se env√≠a a la IA. |
| `model` | string | No | El modelo de IA a utilizar (ej: `gpt-3.5-turbo`, `gemini-pro`, `Llama2:7b-chat`). Si no se env√≠a, usa el configurado por defecto. |
| `context` | number[] | No | Array de n√∫meros (tokens) que representa el historial de la conversaci√≥n (solo para Ollama). |
| `chatId` | string | No | ID de un chat existente para continuar la conversaci√≥n. Si no se env√≠a, se crea un nuevo chat. |

#### Ejemplo de Petici√≥n (Nuevo Chat)

```json
{
  "message": "Hola, ¬øc√≥mo puedo estructurar un curso de Python?",
  "model": "gpt-3.5-turbo" // Opcional
}
```

#### Ejemplo de Petici√≥n (Continuar Chat)

```json
{
  "message": "¬øY qu√© temas deber√≠a incluir?",
  "chatId": "6924ee716f476c51e6fc51df"
}
```

#### Respuesta Exitosa

**C√≥digo:** `200 OK`

```json
{
  "success": true,
  "chatId": "6924ee716f476c51e6fc51df",
  "response": "Texto de la respuesta...",
  "context": [1, 2, 3, ...] // Solo para modelos Ollama
}
```

#### Notas Importantes

**Sobre el `chatId`:**
- Cuando env√≠as el primer mensaje sin `chatId`, el sistema crea un nuevo chat y devuelve un `chatId`.
- Guarda este `chatId` en tu aplicaci√≥n cliente para continuar la conversaci√≥n.
- Env√≠a el mismo `chatId` en las siguientes peticiones para mantener el historial.
- Todos los mensajes (usuario y asistente) se guardan autom√°ticamente en la base de datos.

**Sobre el `context` (solo Ollama):**
- Solo los modelos de Ollama usan el array num√©rico `context` para mantener el historial.
- Para OpenAI y Gemini, el historial se reconstruye autom√°ticamente desde la base de datos.
- Si cambias de modelo dentro de la misma conversaci√≥n, el `context` num√©rico no es compatible entre modelos diferentes.

**Modelos Soportados:**
- **Ollama**: `Llama2:7b-chat`, `deepseek-r1:7b`
- **OpenAI**: `gpt-3.5-turbo`, `gpt-4`
- **Google Gemini**: `gemini-2.0-flash`

#### Ejemplo de Flujo Completo

**Paso 1: Primera Pregunta (Sin chatId)**
```bash
curl -X POST http://localhost:3003/api/v1/ai/chat \
  -H "Content-Type: application/json" \
  -d '{"message":"¬øPor qu√© el cielo es azul?"}'
```

**Respuesta:**
```json
{
  "success": true,
  "chatId": "6924ee716f476c51e6fc51df",
  "response": "El cielo es azul debido a la dispersi√≥n de Rayleigh...",
  "context": [123, 456, 789, ...]
}
```

**Paso 2: Segunda Pregunta (Con chatId para continuar)**
```bash
curl -X POST http://localhost:3003/api/v1/ai/chat \
  -H "Content-Type: application/json" \
  -d '{"message":"¬øY por qu√© se pone rojo al atardecer?","chatId":"6924ee716f476c51e6fc51df"}'
```

**Respuesta:**
```json
{
  "success": true,
  "chatId": "6924ee716f476c51e6fc51df",
  "response": "Al atardecer, la luz recorre m√°s distancia...",
  "context": [123, 456, 789, 1011, 1213, ...]
}
```

#### Respuesta de Error

**C√≥digo:** `400 Bad Request`
```json
{
  "success": false,
  "error": "Missing required field: message",
  "timestamp": "2023-10-27T10:00:00.000Z"
}
```

---

## üìö Gesti√≥n de Historial de Chats

URL Base: `/api/v1/chats`

### 3. Listar Todos los Chats

Obtiene una lista de todos los chats guardados en la base de datos.

**Endpoint:** `GET /chats`

#### Respuesta Exitosa

**C√≥digo:** `200 OK`

```json
{
  "success": true,
  "count": 1,
  "data": [
    {
      "chatId": "6924ee716f476c51e6fc51df",
      "createdAt": "2025-11-24T23:47:04.596Z",
      "updatedAt": "2025-11-24T23:47:23.002Z",
      "messageCount": 4,
      "lastMessage": "La capital de Francia es Par√≠s."
    }
  ]
}
```

#### Ejemplo de Petici√≥n

```bash
curl http://localhost:3003/api/v1/chats
```

---

### 4. Obtener Historial de un Chat

Obtiene el historial completo de mensajes de un chat espec√≠fico.

**Endpoint:** `GET /chats/:id`

#### Par√°metros de URL

| Par√°metro | Tipo | Descripci√≥n |
|-----------|------|-------------|
| `id` | string | ID del chat a consultar |

#### Respuesta Exitosa

**C√≥digo:** `200 OK`

```json
{
  "success": true,
  "data": {
    "chatId": "6924ee716f476c51e6fc51df",
    "messages": [
      {
        "role": "user",
        "content": "Hola, ¬øc√≥mo est√°s?",
        "timestamp": "2025-11-24T23:46:57.017Z"
      },
      {
        "role": "assistant",
        "content": "Hola! Estoy bien, gracias por preguntar.",
        "context": [123, 456, ...],
        "timestamp": "2025-11-24T23:47:04.592Z"
      }
    ],
    "createdAt": "2025-11-24T23:47:04.596Z",
    "updatedAt": "2025-11-24T23:47:23.002Z"
  }
}
```

#### Respuesta de Error

**C√≥digo:** `404 Not Found`
```json
{
  "success": false,
  "error": "Chat not found"
}
```

#### Ejemplo de Petici√≥n

```bash
curl http://localhost:3003/api/v1/chats/6924ee716f476c51e6fc51df
```

---

### 5. Eliminar un Chat

Elimina permanentemente un chat y todo su historial.

**Endpoint:** `DELETE /chats/:id`

#### Par√°metros de URL

| Par√°metro | Tipo | Descripci√≥n |
|-----------|------|-------------|
| `id` | string | ID del chat a eliminar |

#### Respuesta Exitosa

**C√≥digo:** `200 OK`

```json
{
  "success": true,
  "message": "Chat deleted successfully"
}
```

#### Respuesta de Error

**C√≥digo:** `404 Not Found`
```json
{
  "success": false,
  "error": "Chat not found"
}
```

#### Ejemplo de Petici√≥n

```bash
curl -X DELETE http://localhost:3003/api/v1/chats/6924ee716f476c51e6fc51df
```

---

### 2. Asistente de Cursos

Genera un esquema de curso estructurado y profesional basado en una idea y pautas de estilo.

**Endpoint:** `POST /course-assistant`

#### Cuerpo de la Petici√≥n

| Campo | Tipo | Requerido | Descripci√≥n |
|-------|------|----------|-------------|
| `idea` | string | S√≠ | El concepto central o tema del curso. |
| `guide` | string | S√≠ | Pautas estructurales, audiencia objetivo o requisitos espec√≠ficos. |
| `model` | string | No | El modelo de IA a utilizar (ej: `llama3.2`, `mistral`). Si no se env√≠a, usa el configurado por defecto. |

#### Ejemplo de Petici√≥n

```json
{
  "idea": "Introducci√≥n a la Programaci√≥n en Python para Ciencia de Datos",
  "guide": "La audiencia objetivo son principiantes. Incluir 4 m√≥dulos principales. Enfocarse en ejemplos pr√°cticos."
}
```

#### Respuesta Exitosa

**C√≥digo:** `200 OK`

```json
{
  "response": "T√≠tulo del Curso: Python para Ciencia de Datos\n\nM√≥dulo 1: Fundamentos de Python\n- Lecci√≥n 1.1: Instalaci√≥n y Configuraci√≥n\n- Lecci√≥n 1.2: Variables y Tipos de Datos..."
}
```

#### Respuesta de Error

**C√≥digo:** `400 Bad Request`
```json
{
  "success": false,
  "error": "Missing required field: idea",
  "timestamp": "2023-10-27T10:00:00.000Z"
}
```


## üõ†Ô∏è Prerrequisitos y Configuraci√≥n

### Proveedores de IA Soportados

El servicio soporta tres proveedores de IA:

1. **Ollama** (Local) - Para modelos open-source ejecutados localmente
2. **OpenAI** - Para GPT-3.5, GPT-4 y variantes
3. **Google Gemini** - Para modelos Gemini Pro y Flash

### 1. Configurar Ollama (Opcional)

Si deseas usar modelos locales con Ollama:

#### Instalar Ollama
- **Descargar:** Visita [ollama.com](https://ollama.com) y descarga la versi√≥n para tu sistema operativo.
- **Instalar:** Sigue las instrucciones del instalador.

#### Descargar Modelos
Descarga los modelos que desees usar:

```bash
ollama pull Llama2:7b-chat
ollama pull llama3.2
ollama pull mistral
```

#### Verificar que Ollama est√° corriendo
Antes de usar modelos de Ollama, aseg√∫rate de que est√© activo:
```bash
curl http://127.0.0.1:11434
```

### 2. Configuraci√≥n de Variables de Entorno (.env)

Aseg√∫rate de que tu archivo `.env` tenga las siguientes variables configuradas:

```dotenv
# Configuraci√≥n del Servidor
PORT=3003
NODE_ENV=development

# Base de Datos MongoDB
MONGO_URI=mongodb+srv://usuario:contrase√±a@cluster.mongodb.net/?appName=app

# Ollama (Local)
OLLAMA_HOST=http://127.0.0.1:11434
OLLAMA_MODEL=Llama2:7b-chat

# OpenAI (Opcional)
OPENAI_API_KEY=sk-tu-api-key-aqui

# Google Gemini (Opcional)
GEMINI_API_KEY=tu-api-key-aqui
```

### 3. Obtener API Keys

#### OpenAI
1. Ve a [platform.openai.com](https://platform.openai.com)
2. Crea una cuenta o inicia sesi√≥n
3. Ve a "API Keys" y genera una nueva clave
4. Copia la clave y agr√©gala a tu `.env` como `OPENAI_API_KEY`

#### Google Gemini
1. Ve a [Google AI Studio](https://aistudio.google.com/app/apikey)
2. Inicia sesi√≥n con tu cuenta de Google
3. Crea una nueva API key
4. Copia la clave y agr√©gala a tu `.env` como `GEMINI_API_KEY`

### 4. Configurar Base de Datos

El servicio requiere MongoDB para almacenar el historial de conversaciones:

1. **Opci√≥n A - MongoDB Atlas (Nube):**
   - Crea una cuenta gratuita en [mongodb.com/cloud/atlas](https://www.mongodb.com/cloud/atlas)
   - Crea un cluster
   - Obt√©n la connection string
   - Agr√©gala a `MONGO_URI` en tu `.env`

2. **Opci√≥n B - MongoDB Local:**
   ```bash
   # Instalar MongoDB localmente
   # Ubuntu/Debian
   sudo apt install mongodb
   
   # macOS
   brew install mongodb-community
   
   # Connection string
   MONGO_URI=mongodb://localhost:27017/sophia-chats
   ```
